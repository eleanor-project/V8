ELEANOR_ENVIRONMENT=development
ELEANOR_ENV=development
# Optional legacy YAML config (lowest precedence)
# ELEANOR_CONFIG=./config/eleanor.yaml

# Adapter keys (supply your own)
OPENAI_KEY=
ANTHROPIC_KEY=
XAI_KEY=
GEMINI_KEY=

# Routing policy (optional cost/latency shaping)
ROUTER_ADAPTER_COSTS={"gpt-4":0.06,"gpt-3.5-turbo":0.002,"claude-3-opus":0.015}
ROUTER_MAX_COST=
ROUTER_ADAPTER_LATENCIES={"gpt-4":1200,"gpt-3.5-turbo":600}
ROUTER_LATENCY_BUDGET_MS=
OLLAMA_MODEL=llama3          # default Ollama model (can be phi3, mistral, etc.)
OLLAMA_MODELS=llama3,phi3    # optional list to register multiple Ollama models
HF_MODELS=meta-llama/Llama-3-8b,microsoft/Phi-3-mini-4k-instruct,mistralai/Mistral-7B-v0.3
HF_DEVICE=cpu

# Precedent and embeddings
PRECEDENT_BACKEND=weaviate  # weaviate|pgvector|memory
EMBEDDING_BACKEND=gpt
WEAVIATE_URL=http://weaviate:8080
PG_CONN_STRING=postgresql://postgres:postgres@pgvector:5432/eleanor
PG_TABLE=precedent

# Governance (OPA)
OPA_URL=http://opa:8181
OPA_POLICY_PATH=v1/data/eleanor/decision
OPA_FAIL_STRATEGY=escalate  # allow|deny|escalate
# Set to 1/true to disable OPA completely (useful for local/dev)
ELEANOR_DISABLE_OPA=0

# Critic model bindings (examples)
# Preferred Ollama model for critics (auto-creates adapter name)
# OLLAMA_CRITIC_MODEL=phi3
# Force all critics to a specific adapter name (e.g., ollama-phi3, gpt, claude)
# CRITIC_DEFAULT_ADAPTER=ollama-phi3
# Explicit per-critic mapping (JSON or critic=adapter pairs)
# CRITIC_MODEL_BINDINGS={"rights":"ollama-phi3","autonomy":"ollama-phi3"}

# Evidence / replay
EVIDENCE_PATH=/app/audit/evidence.jsonl
REPLAY_LOG_PATH=/app/audit/replay_log.jsonl

# Metrics / tracing
ENABLE_PROMETHEUS_MIDDLEWARE=1
ENABLE_OTEL=0
OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318/v1/traces
OTEL_SERVICE_NAME=eleanor-v8-api

# Security
MAX_REQUEST_BYTES=1048576
CORS_ORIGINS=http://localhost:3000
JWT_SECRET=

# Rate limiting (if applicable)
RATE_LIMIT_REQUESTS_PER_WINDOW=30
RATE_LIMIT_WINDOW_SECONDS=60
